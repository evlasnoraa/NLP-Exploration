{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9CljCDmcQpQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import make_scorer, accuracy_score, f1_score\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import roc_auc_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hWkwMLLcuL3",
        "outputId": "2d1b8b09-8898-4c42-e105-fd49e81c72c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Logistic Regression with TF-IDF Vectorization**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yNUTZkqZ_MzT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Step 1 - Data Preparation**"
      ],
      "metadata": {
        "id": "vpI0j8ekBCZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I first save data in pandas dataframe and then split it into training, validation and test set."
      ],
      "metadata": {
        "id": "Y_7qMZ35BNmS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UizOyuhyc5LU",
        "outputId": "33db2432-4367-4041-b9c7-231d2b0937d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              Review Rating\n",
            "0  Our 2008 Town & Country shuts off while drivin...    neg\n",
            "1  I purchased this new in 2012 and paid cash for...    neg\n",
            "2  Update:  12/28/2019 - GPS/INFOTAINMENT SCREEN ...    neg\n",
            "3  I thought I was getting a good deal. A mint fu...    neg\n",
            "4  I have had a rattle in my new VW atlas after t...    neg\n"
          ]
        }
      ],
      "source": [
        "# Load our Excel data into a pandas DataFrame\n",
        "df = pd.read_csv('Review.csv')\n",
        "\n",
        "# Select only the 'review' and 'rating' columns\n",
        "df_filtered = df[['Review', 'Rating']]\n",
        "\n",
        "val = df_filtered['Rating'].value_counts()[1]\n",
        "\n",
        "# Get 10,000 instances of reviews with rating 1\n",
        "df_rating_1 = df_filtered[df_filtered['Rating'] == 1].sample(n=val, random_state=1)\n",
        "\n",
        "# Get 10,000 random samples for ratings 2, 3, 4, and 5 to balance the dataset\n",
        "df_rating_2 = df_filtered[df_filtered['Rating'] == 2].sample(n=val, random_state=1)\n",
        "df_rating_4 = df_filtered[df_filtered['Rating'] == 4].sample(n=val, random_state=1)\n",
        "df_rating_5 = df_filtered[df_filtered['Rating'] == 5].sample(n=val, random_state=1)\n",
        "\n",
        "# Combine the samples into a single DataFrame\n",
        "balanced_df = pd.concat([df_rating_1, df_rating_2, df_rating_4, df_rating_5])\n",
        "\n",
        "# Relabel the ratings\n",
        "# 1 and 2 -> neg, 3 -> nil, 4 and 5 -> pos\n",
        "def relabel_rating(rating):\n",
        "    if rating in [1, 2]:\n",
        "        return 'neg'\n",
        "    elif rating in [4, 5]:\n",
        "        return 'pos'\n",
        "\n",
        "# Apply the relabeling function to the 'rating' column\n",
        "balanced_df['Rating'] = balanced_df['Rating'].apply(relabel_rating)\n",
        "\n",
        "# Reset the index for neatness\n",
        "balanced_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Removing nan values\n",
        "balanced_df.dropna(inplace=True)\n",
        "\n",
        "# Display the first few rows of the final DataFrame\n",
        "print(balanced_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XydfPL4geFSF"
      },
      "outputs": [],
      "source": [
        "#Creating a randomized vector whose length is the length of our dataset\n",
        "total_count = balanced_df.shape[0]\n",
        "np.random.seed(0)\n",
        "shuffle = np.random.permutation(total_count)\n",
        "\n",
        "#Splitting the dataset into 'x' and 'y', so that it can be used in our model\n",
        "#'x' represents the reviews and 'y' represents the sentiments\n",
        "x = balanced_df.iloc[shuffle, 0]\n",
        "y = balanced_df.iloc[shuffle, 1]\n",
        "\n",
        "#splitting the dataset in training and testing sets in a 80:20 ratio\n",
        "split = int(total_count * 0.6) + 1  #the required 80% split\n",
        "split_2 = int(total_count *0.8) + 1\n",
        "x_train = x[:split]\n",
        "y_train = y[:split]\n",
        "\n",
        "x_val = x[split:split_2]\n",
        "y_val = y[split:split_2]\n",
        "\n",
        "x_test = x[split_2:]\n",
        "y_test = y[split_2:]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**review_cleaner** function performs stemming on our reviews, turns them into lowercase and then also removes stop words. Returns a simplified sentence that can be used for GridSearchCV"
      ],
      "metadata": {
        "id": "o31dxow2_9IV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wE8VHFUWeyXM"
      },
      "outputs": [],
      "source": [
        "def review_cleaner(review):\n",
        "  stopwords = nltk.corpus.stopwords.words(\"english\")\n",
        "  porter = PorterStemmer()\n",
        "  # Make sure the reviews are not case sensitive\n",
        "  review = review.lower()\n",
        "  # Tokenize the words from the review\n",
        "  words = nltk.word_tokenize(review)\n",
        "  # Stemming and stopwords removal\n",
        "  processed_words = [porter.stem(word) for word in words if word not in stopwords]\n",
        "  # Join back to a single string\n",
        "  return ' '.join(processed_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "##**Step 2 - Hyperparameter Tuning using GridSearchCV**\n"
      ],
      "metadata": {
        "id": "4iSPMEy6BlvY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used the **GridSearchCV** function from sklearn library to perform hyperparameter tuning and choose the optimal values for n-gram size, C and l1 ratio.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QYOqJRl2CAab"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWuzNPnZeWmz",
        "outputId": "9ab64c44-567c-4a3d-ec26-fa5ab73973fd"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
            "[CV] END model__C=0.01, model__l1_ratio=0.1, tfidf__ngram_range=(1, 1); total time= 1.4min\n",
            "[CV] END model__C=0.01, model__l1_ratio=0.1, tfidf__ngram_range=(1, 1); total time= 1.4min\n",
            "[CV] END model__C=0.01, model__l1_ratio=0.1, tfidf__ngram_range=(1, 1); total time= 1.4min\n",
            "[CV] END model__C=0.01, model__l1_ratio=0.1, tfidf__ngram_range=(1, 2); total time= 1.5min\n",
            "[CV] END model__C=0.01, model__l1_ratio=0.1, tfidf__ngram_range=(1, 2); total time= 1.5min\n",
            "[CV] END model__C=0.01, model__l1_ratio=0.1, tfidf__ngram_range=(1, 2); total time= 1.5min\n",
            "[CV] END model__C=0.01, model__l1_ratio=0.1, tfidf__ngram_range=(1, 3); total time= 1.8min\n",
            "[CV] END model__C=0.01, model__l1_ratio=0.1, tfidf__ngram_range=(1, 3); total time= 1.6min\n",
            "[CV] END model__C=0.01, model__l1_ratio=0.1, tfidf__ngram_range=(1, 3); total time= 1.6min\n",
            "[CV] END model__C=0.01, model__l1_ratio=0.5, tfidf__ngram_range=(1, 1); total time= 1.4min\n",
            "[CV] END model__C=0.01, model__l1_ratio=0.5, tfidf__ngram_range=(1, 1); total time= 1.4min\n",
            "[CV] END model__C=0.01, model__l1_ratio=0.5, tfidf__ngram_range=(1, 1); total time= 1.4min\n",
            "[CV] END model__C=0.01, model__l1_ratio=0.5, tfidf__ngram_range=(1, 2); total time= 1.5min\n",
            "[CV] END model__C=0.01, model__l1_ratio=0.5, tfidf__ngram_range=(1, 2); total time= 1.5min\n",
            "[CV] END model__C=0.01, model__l1_ratio=0.5, tfidf__ngram_range=(1, 2); total time= 1.5min\n",
            "[CV] END model__C=0.01, model__l1_ratio=0.5, tfidf__ngram_range=(1, 3); total time= 1.6min\n",
            "[CV] END model__C=0.01, model__l1_ratio=0.5, tfidf__ngram_range=(1, 3); total time= 1.6min\n",
            "[CV] END model__C=0.01, model__l1_ratio=0.5, tfidf__ngram_range=(1, 3); total time= 1.6min\n",
            "[CV] END model__C=0.01, model__l1_ratio=0.9, tfidf__ngram_range=(1, 1); total time= 1.4min\n",
            "[CV] END model__C=0.01, model__l1_ratio=0.9, tfidf__ngram_range=(1, 1); total time= 1.4min\n",
            "[CV] END model__C=0.01, model__l1_ratio=0.9, tfidf__ngram_range=(1, 1); total time= 1.4min\n",
            "[CV] END model__C=0.01, model__l1_ratio=0.9, tfidf__ngram_range=(1, 2); total time= 1.5min\n",
            "[CV] END model__C=0.01, model__l1_ratio=0.9, tfidf__ngram_range=(1, 2); total time= 1.5min\n",
            "[CV] END model__C=0.01, model__l1_ratio=0.9, tfidf__ngram_range=(1, 2); total time= 1.5min\n",
            "[CV] END model__C=0.01, model__l1_ratio=0.9, tfidf__ngram_range=(1, 3); total time= 1.6min\n",
            "[CV] END model__C=0.01, model__l1_ratio=0.9, tfidf__ngram_range=(1, 3); total time= 1.6min\n",
            "[CV] END model__C=0.01, model__l1_ratio=0.9, tfidf__ngram_range=(1, 3); total time= 1.6min\n",
            "[CV] END model__C=0.1, model__l1_ratio=0.1, tfidf__ngram_range=(1, 1); total time= 1.5min\n",
            "[CV] END model__C=0.1, model__l1_ratio=0.1, tfidf__ngram_range=(1, 1); total time= 1.4min\n",
            "[CV] END model__C=0.1, model__l1_ratio=0.1, tfidf__ngram_range=(1, 1); total time= 1.4min\n",
            "[CV] END model__C=0.1, model__l1_ratio=0.1, tfidf__ngram_range=(1, 2); total time= 1.6min\n",
            "[CV] END model__C=0.1, model__l1_ratio=0.1, tfidf__ngram_range=(1, 2); total time= 1.6min\n",
            "[CV] END model__C=0.1, model__l1_ratio=0.1, tfidf__ngram_range=(1, 2); total time= 1.5min\n",
            "[CV] END model__C=0.1, model__l1_ratio=0.1, tfidf__ngram_range=(1, 3); total time= 1.7min\n",
            "[CV] END model__C=0.1, model__l1_ratio=0.1, tfidf__ngram_range=(1, 3); total time= 1.7min\n",
            "[CV] END model__C=0.1, model__l1_ratio=0.1, tfidf__ngram_range=(1, 3); total time= 1.6min\n",
            "[CV] END model__C=0.1, model__l1_ratio=0.5, tfidf__ngram_range=(1, 1); total time= 1.4min\n",
            "[CV] END model__C=0.1, model__l1_ratio=0.5, tfidf__ngram_range=(1, 1); total time= 1.4min\n",
            "[CV] END model__C=0.1, model__l1_ratio=0.5, tfidf__ngram_range=(1, 1); total time= 1.4min\n",
            "[CV] END model__C=0.1, model__l1_ratio=0.5, tfidf__ngram_range=(1, 2); total time= 1.5min\n",
            "[CV] END model__C=0.1, model__l1_ratio=0.5, tfidf__ngram_range=(1, 2); total time= 1.5min\n",
            "[CV] END model__C=0.1, model__l1_ratio=0.5, tfidf__ngram_range=(1, 2); total time= 1.5min\n",
            "[CV] END model__C=0.1, model__l1_ratio=0.5, tfidf__ngram_range=(1, 3); total time= 1.6min\n",
            "[CV] END model__C=0.1, model__l1_ratio=0.5, tfidf__ngram_range=(1, 3); total time= 1.6min\n",
            "[CV] END model__C=0.1, model__l1_ratio=0.5, tfidf__ngram_range=(1, 3); total time= 1.5min\n",
            "[CV] END model__C=0.1, model__l1_ratio=0.9, tfidf__ngram_range=(1, 1); total time= 1.4min\n",
            "[CV] END model__C=0.1, model__l1_ratio=0.9, tfidf__ngram_range=(1, 1); total time= 1.4min\n",
            "[CV] END model__C=0.1, model__l1_ratio=0.9, tfidf__ngram_range=(1, 1); total time= 1.4min\n",
            "[CV] END model__C=0.1, model__l1_ratio=0.9, tfidf__ngram_range=(1, 2); total time= 1.5min\n",
            "[CV] END model__C=0.1, model__l1_ratio=0.9, tfidf__ngram_range=(1, 2); total time= 1.5min\n",
            "[CV] END model__C=0.1, model__l1_ratio=0.9, tfidf__ngram_range=(1, 2); total time= 1.5min\n",
            "[CV] END model__C=0.1, model__l1_ratio=0.9, tfidf__ngram_range=(1, 3); total time= 1.6min\n",
            "[CV] END model__C=0.1, model__l1_ratio=0.9, tfidf__ngram_range=(1, 3); total time= 1.6min\n",
            "[CV] END model__C=0.1, model__l1_ratio=0.9, tfidf__ngram_range=(1, 3); total time= 1.6min\n",
            "[CV] END model__C=1, model__l1_ratio=0.1, tfidf__ngram_range=(1, 1); total time= 1.5min\n",
            "[CV] END model__C=1, model__l1_ratio=0.1, tfidf__ngram_range=(1, 1); total time= 1.6min\n",
            "[CV] END model__C=1, model__l1_ratio=0.1, tfidf__ngram_range=(1, 1); total time= 1.6min\n",
            "[CV] END model__C=1, model__l1_ratio=0.1, tfidf__ngram_range=(1, 2); total time= 1.7min\n",
            "[CV] END model__C=1, model__l1_ratio=0.1, tfidf__ngram_range=(1, 2); total time= 1.7min\n",
            "[CV] END model__C=1, model__l1_ratio=0.1, tfidf__ngram_range=(1, 2); total time= 1.7min\n",
            "[CV] END model__C=1, model__l1_ratio=0.1, tfidf__ngram_range=(1, 3); total time= 1.8min\n",
            "[CV] END model__C=1, model__l1_ratio=0.1, tfidf__ngram_range=(1, 3); total time= 1.8min\n",
            "[CV] END model__C=1, model__l1_ratio=0.1, tfidf__ngram_range=(1, 3); total time= 1.8min\n",
            "[CV] END model__C=1, model__l1_ratio=0.5, tfidf__ngram_range=(1, 1); total time= 1.4min\n",
            "[CV] END model__C=1, model__l1_ratio=0.5, tfidf__ngram_range=(1, 1); total time= 1.4min\n",
            "[CV] END model__C=1, model__l1_ratio=0.5, tfidf__ngram_range=(1, 1); total time= 1.5min\n",
            "[CV] END model__C=1, model__l1_ratio=0.5, tfidf__ngram_range=(1, 2); total time= 1.6min\n",
            "[CV] END model__C=1, model__l1_ratio=0.5, tfidf__ngram_range=(1, 2); total time= 1.6min\n",
            "[CV] END model__C=1, model__l1_ratio=0.5, tfidf__ngram_range=(1, 2); total time= 1.6min\n",
            "[CV] END model__C=1, model__l1_ratio=0.5, tfidf__ngram_range=(1, 3); total time= 1.7min\n",
            "[CV] END model__C=1, model__l1_ratio=0.5, tfidf__ngram_range=(1, 3); total time= 1.7min\n",
            "[CV] END model__C=1, model__l1_ratio=0.5, tfidf__ngram_range=(1, 3); total time= 1.7min\n",
            "[CV] END model__C=1, model__l1_ratio=0.9, tfidf__ngram_range=(1, 1); total time= 1.5min\n",
            "[CV] END model__C=1, model__l1_ratio=0.9, tfidf__ngram_range=(1, 1); total time= 1.5min\n",
            "[CV] END model__C=1, model__l1_ratio=0.9, tfidf__ngram_range=(1, 1); total time= 1.5min\n",
            "[CV] END model__C=1, model__l1_ratio=0.9, tfidf__ngram_range=(1, 2); total time= 1.6min\n",
            "[CV] END model__C=1, model__l1_ratio=0.9, tfidf__ngram_range=(1, 2); total time= 1.7min\n",
            "[CV] END model__C=1, model__l1_ratio=0.9, tfidf__ngram_range=(1, 2); total time= 1.6min\n",
            "[CV] END model__C=1, model__l1_ratio=0.9, tfidf__ngram_range=(1, 3); total time= 1.7min\n",
            "[CV] END model__C=1, model__l1_ratio=0.9, tfidf__ngram_range=(1, 3); total time= 1.8min\n",
            "[CV] END model__C=1, model__l1_ratio=0.9, tfidf__ngram_range=(1, 3); total time= 1.8min\n",
            "[CV] END model__C=10, model__l1_ratio=0.1, tfidf__ngram_range=(1, 1); total time= 2.2min\n",
            "[CV] END model__C=10, model__l1_ratio=0.1, tfidf__ngram_range=(1, 1); total time= 2.2min\n",
            "[CV] END model__C=10, model__l1_ratio=0.1, tfidf__ngram_range=(1, 1); total time= 2.3min\n",
            "[CV] END model__C=10, model__l1_ratio=0.1, tfidf__ngram_range=(1, 2); total time= 2.3min\n",
            "[CV] END model__C=10, model__l1_ratio=0.1, tfidf__ngram_range=(1, 2); total time= 2.3min\n",
            "[CV] END model__C=10, model__l1_ratio=0.1, tfidf__ngram_range=(1, 2); total time= 2.4min\n",
            "[CV] END model__C=10, model__l1_ratio=0.1, tfidf__ngram_range=(1, 3); total time= 2.5min\n",
            "[CV] END model__C=10, model__l1_ratio=0.1, tfidf__ngram_range=(1, 3); total time= 2.3min\n",
            "[CV] END model__C=10, model__l1_ratio=0.1, tfidf__ngram_range=(1, 3); total time= 2.4min\n",
            "[CV] END model__C=10, model__l1_ratio=0.5, tfidf__ngram_range=(1, 1); total time= 2.3min\n",
            "[CV] END model__C=10, model__l1_ratio=0.5, tfidf__ngram_range=(1, 1); total time= 2.3min\n",
            "[CV] END model__C=10, model__l1_ratio=0.5, tfidf__ngram_range=(1, 1); total time= 2.3min\n",
            "[CV] END model__C=10, model__l1_ratio=0.5, tfidf__ngram_range=(1, 2); total time= 2.5min\n",
            "[CV] END model__C=10, model__l1_ratio=0.5, tfidf__ngram_range=(1, 2); total time= 2.4min\n",
            "[CV] END model__C=10, model__l1_ratio=0.5, tfidf__ngram_range=(1, 2); total time= 2.4min\n",
            "[CV] END model__C=10, model__l1_ratio=0.5, tfidf__ngram_range=(1, 3); total time= 2.6min\n",
            "[CV] END model__C=10, model__l1_ratio=0.5, tfidf__ngram_range=(1, 3); total time= 2.5min\n",
            "[CV] END model__C=10, model__l1_ratio=0.5, tfidf__ngram_range=(1, 3); total time= 2.6min\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END model__C=10, model__l1_ratio=0.9, tfidf__ngram_range=(1, 1); total time= 2.8min\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END model__C=10, model__l1_ratio=0.9, tfidf__ngram_range=(1, 1); total time= 2.8min\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END model__C=10, model__l1_ratio=0.9, tfidf__ngram_range=(1, 1); total time= 2.8min\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END model__C=10, model__l1_ratio=0.9, tfidf__ngram_range=(1, 2); total time= 3.0min\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END model__C=10, model__l1_ratio=0.9, tfidf__ngram_range=(1, 2); total time= 3.0min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END model__C=10, model__l1_ratio=0.9, tfidf__ngram_range=(1, 2); total time= 3.0min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END model__C=10, model__l1_ratio=0.9, tfidf__ngram_range=(1, 3); total time= 3.2min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END model__C=10, model__l1_ratio=0.9, tfidf__ngram_range=(1, 3); total time= 3.2min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END model__C=10, model__l1_ratio=0.9, tfidf__ngram_range=(1, 3); total time= 3.1min\n",
            "Best parameters found: {'model__C': 1, 'model__l1_ratio': 0.1, 'tfidf__ngram_range': (1, 3)}\n",
            "Best F1 score: 0.9205718749216212\n"
          ]
        }
      ],
      "source": [
        "# Updated param grids with limited ranges\n",
        "param_distributions = {\n",
        "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
        "    'model__C': [0.01, 0.1, 1, 10],\n",
        "    'model__l1_ratio': [0.1, 0.5, 0.9]\n",
        "}\n",
        "\n",
        "# Pipeline definition\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(preprocessor=review_cleaner, max_features = 7000)),\n",
        "    ('model', LogisticRegression(max_iter=200, solver='saga', penalty = 'elasticnet'))\n",
        "])\n",
        "\n",
        "# Randomized search with parallel processing and reduced sample size\n",
        "random_search = GridSearchCV(\n",
        "    pipeline,\n",
        "    param_grid=param_distributions,\n",
        "    scoring='f1_weighted',\n",
        "    refit=True,\n",
        "    cv=3,  # Reduced to 2-fold CV for faster tuning\n",
        "    verbose=2,\n",
        ")\n",
        "\n",
        "# Fit on a sample of the training data\n",
        "random_search.fit(x_train, y_train)\n",
        "\n",
        "# Output best parameters and score\n",
        "print(\"Best parameters found:\", random_search.best_params_)\n",
        "print(\"Best F1 score:\", random_search.best_score_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "##**Step 3 - Model fitting, prediction and performance scores**"
      ],
      "metadata": {
        "id": "6thXN4i5IImB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model(s) were fit on just the training set to save time. However, once the optimized values were found, the model with the optimal parameters was fit on training and validaiton sets."
      ],
      "metadata": {
        "id": "P37LhSlTFFDn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Refit on x_train + x_val with best parameters\n",
        "best_model = random_search.best_estimator_\n",
        "best_model.fit(np.concatenate([x_train, x_val]), np.concatenate([y_train, y_val]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "OUkX81HsyY6n",
        "outputId": "09c7b9fd-3072-4478-e193-993e285b8845"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tfidf',\n",
              "                 TfidfVectorizer(max_features=7000, ngram_range=(1, 3),\n",
              "                                 preprocessor=<function review_cleaner at 0x784a1dcfe290>)),\n",
              "                ('model',\n",
              "                 LogisticRegression(C=1, l1_ratio=0.1, max_iter=200,\n",
              "                                    penalty='elasticnet', solver='saga'))])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
              "                 TfidfVectorizer(max_features=7000, ngram_range=(1, 3),\n",
              "                                 preprocessor=&lt;function review_cleaner at 0x784a1dcfe290&gt;)),\n",
              "                (&#x27;model&#x27;,\n",
              "                 LogisticRegression(C=1, l1_ratio=0.1, max_iter=200,\n",
              "                                    penalty=&#x27;elasticnet&#x27;, solver=&#x27;saga&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
              "                 TfidfVectorizer(max_features=7000, ngram_range=(1, 3),\n",
              "                                 preprocessor=&lt;function review_cleaner at 0x784a1dcfe290&gt;)),\n",
              "                (&#x27;model&#x27;,\n",
              "                 LogisticRegression(C=1, l1_ratio=0.1, max_iter=200,\n",
              "                                    penalty=&#x27;elasticnet&#x27;, solver=&#x27;saga&#x27;))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;TfidfVectorizer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfVectorizer(max_features=7000, ngram_range=(1, 3),\n",
              "                preprocessor=&lt;function review_cleaner at 0x784a1dcfe290&gt;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(C=1, l1_ratio=0.1, max_iter=200, penalty=&#x27;elasticnet&#x27;,\n",
              "                   solver=&#x27;saga&#x27;)</pre></div> </div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred = best_model.predict(x_test)\n",
        "new_test_f1_score = f1_score(y_test, y_test_pred, average='weighted')\n",
        "new_test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "print(\"Test F1 Score:\", new_test_f1_score)\n",
        "print(\"Test Accuracy:\", new_test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBE0w4KHyxIS",
        "outputId": "488cfa8c-07a5-41db-d0cf-7d8ec4400be9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test F1 Score: 0.9289015252487914\n",
            "Test Accuracy: 0.9289045614833352\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Since the hyperparameter tuning for C = 10, l1_ratio = 0.9 ran out because of iteration limits, I ran it again using a higher iteration cap."
      ],
      "metadata": {
        "id": "wPFAaTAbFHpw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Updated param grids with limited ranges\n",
        "param_distributions = {\n",
        "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
        "}\n",
        "\n",
        "# Pipeline definition\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(preprocessor=review_cleaner, max_features = 7000)),\n",
        "    ('model', LogisticRegression(max_iter=500, solver='saga', penalty = 'elasticnet', C = 10, l1_ratio = 0.9))\n",
        "])\n",
        "\n",
        "# Randomized search with parallel processing and reduced sample size\n",
        "random_search = GridSearchCV(\n",
        "    pipeline,\n",
        "    param_grid=param_distributions,\n",
        "    scoring='f1_weighted',\n",
        "    refit=True,\n",
        "    cv=3,  # Reduced to 2-fold CV for faster tuning\n",
        "    verbose=2,\n",
        ")\n",
        "\n",
        "# Fit on a sample of the training data\n",
        "random_search.fit(np.concatenate([x_train, x_val]), np.concatenate([y_train, y_val]))\n",
        "\n",
        "# Output best parameters and score\n",
        "print(\"Best parameters found:\", random_search.best_params_)\n",
        "print(\"Best F1 score:\", random_search.best_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAPvWNOLzgWk",
        "outputId": "203e5982-219e-4c28-d9f6-0ec29f1eae99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
            "[CV] END ..........................tfidf__ngram_range=(1, 1); total time= 4.7min\n",
            "[CV] END ..........................tfidf__ngram_range=(1, 1); total time= 4.5min\n",
            "[CV] END ..........................tfidf__ngram_range=(1, 1); total time= 4.5min\n",
            "[CV] END ..........................tfidf__ngram_range=(1, 2); total time= 4.9min\n",
            "[CV] END ..........................tfidf__ngram_range=(1, 2); total time= 4.7min\n",
            "[CV] END ..........................tfidf__ngram_range=(1, 2); total time= 4.7min\n",
            "[CV] END ..........................tfidf__ngram_range=(1, 3); total time= 5.1min\n",
            "[CV] END ..........................tfidf__ngram_range=(1, 3); total time= 4.7min\n",
            "[CV] END ..........................tfidf__ngram_range=(1, 3); total time= 5.1min\n",
            "Best parameters found: {'tfidf__ngram_range': (1, 2)}\n",
            "Best F1 score: 0.9173417245573581\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2 = random_search.best_estimator_\n",
        "y_test_pred_2 = model_2.predict(x_test)\n",
        "poss_test_f1_score = f1_score(y_test, y_test_pred_2, average='weighted')\n",
        "poss_test_accuracy = accuracy_score(y_test, y_test_pred_2)\n",
        "\n",
        "print(\"Test F1 Score:\", poss_test_f1_score)\n",
        "print(\"Test Accuracy:\", poss_test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwWlcr-6ApA-",
        "outputId": "de899149-b879-4a33-a10c-4a61d4cc490e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test F1 Score: 0.919119421843731\n",
            "Test Accuracy: 0.9191218291434422\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Used ROC-AUC on best_model because it had better results than model_2"
      ],
      "metadata": {
        "id": "dPbPbafS3Jib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict probabilities for the test set on the best_model\n",
        "y_test_proba = best_model.predict_proba(x_test)[:,1]\n",
        "# Calculate ROC-AUC score for the test set\n",
        "test_roc_auc = roc_auc_score(np.array(y_test), y_test_proba, multi_class='ovr', average='weighted')\n",
        "print(\"Test ROC-AUC Score:\", test_roc_auc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_QhVqXZBkzH",
        "outputId": "34bb0af6-5815-4769-c660-8ae887d75e00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test ROC-AUC Score: 0.9784484922795849\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "0oWdnxAMJxWL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#**Linear SVM Model**"
      ],
      "metadata": {
        "id": "sVosTdjRDmqU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Step 1 - Re-split the data**\n",
        "\n",
        "I re-split the data into just training and test set. This will take more time, but will make use of all datapoints at our disposal."
      ],
      "metadata": {
        "id": "nPO199PRIEAw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a randomized vector whose length is the length of our dataset\n",
        "total_count = balanced_df.shape[0]\n",
        "np.random.seed(0)\n",
        "shuffle = np.random.permutation(total_count)\n",
        "\n",
        "#Splitting the dataset into 'x' and 'y', so that it can be used in our model\n",
        "#'x' represents the reviews and 'y' represents the sentiments\n",
        "x = balanced_df.iloc[shuffle, 0]\n",
        "y = balanced_df.iloc[shuffle, 1]\n",
        "\n",
        "#splitting the dataset in training and testing sets in a 80:20 ratio\n",
        "split = int(total_count *0.8) + 1\n",
        "x_train = x[:split]\n",
        "y_train = y[:split]\n",
        "\n",
        "x_test = x[split:]\n",
        "y_test = y[split:]"
      ],
      "metadata": {
        "id": "k-5q36YP1KKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Step 2 - Hyperparameter tuning using GridSearchCV**"
      ],
      "metadata": {
        "id": "CvUfvCIOKFVV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameter grid with n-gram range, penalty, and C values\n",
        "param_grid = {\n",
        "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],    # Unigram, bigram, and trigram\n",
        "    'model__penalty': ['l1', 'l2'],                          # 'l1' only available if 'dual=False' in LinearSVC\n",
        "    'model__C': [0.01, 0.1, 1, 10],                    # Regularization parameter\n",
        "}\n",
        "\n",
        "# Pipeline setup\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(preprocessor=review_cleaner, max_features=7000)),  # Include your review cleaning function here\n",
        "    ('model', LinearSVC(max_iter=2000))\n",
        "])\n",
        "\n",
        "# Grid search with 3-fold cross-validation\n",
        "grid_search = GridSearchCV(\n",
        "    pipeline,\n",
        "    param_grid=param_grid,\n",
        "    scoring='f1_weighted',\n",
        "    refit=True,\n",
        "    cv=3,          # 3-fold cross-validation\n",
        "    verbose=2,\n",
        ")\n",
        "\n",
        "# Fit the grid search on training data\n",
        "grid_search.fit(x_train, y_train)\n",
        "\n",
        "# Output best parameters and score\n",
        "print(\"Best parameters found:\", grid_search.best_params_)\n",
        "print(\"Best F1 score:\", grid_search.best_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PEcOkfX_FXT",
        "outputId": "e1a2f87e-6bde-4674-fdff-53f3efd8e1a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
            "[CV] END model__C=0.01, model__penalty=l1, tfidf__ngram_range=(1, 1); total time= 2.2min\n",
            "[CV] END model__C=0.01, model__penalty=l1, tfidf__ngram_range=(1, 1); total time= 2.0min\n",
            "[CV] END model__C=0.01, model__penalty=l1, tfidf__ngram_range=(1, 1); total time= 2.1min\n",
            "[CV] END model__C=0.01, model__penalty=l1, tfidf__ngram_range=(1, 2); total time= 2.1min\n",
            "[CV] END model__C=0.01, model__penalty=l1, tfidf__ngram_range=(1, 2); total time= 2.2min\n",
            "[CV] END model__C=0.01, model__penalty=l1, tfidf__ngram_range=(1, 2); total time= 2.1min\n",
            "[CV] END model__C=0.01, model__penalty=l1, tfidf__ngram_range=(1, 3); total time= 2.3min\n",
            "[CV] END model__C=0.01, model__penalty=l1, tfidf__ngram_range=(1, 3); total time= 2.3min\n",
            "[CV] END model__C=0.01, model__penalty=l1, tfidf__ngram_range=(1, 3); total time= 2.3min\n",
            "[CV] END model__C=0.01, model__penalty=l2, tfidf__ngram_range=(1, 1); total time= 2.0min\n",
            "[CV] END model__C=0.01, model__penalty=l2, tfidf__ngram_range=(1, 1); total time= 2.0min\n",
            "[CV] END model__C=0.01, model__penalty=l2, tfidf__ngram_range=(1, 1); total time= 2.0min\n",
            "[CV] END model__C=0.01, model__penalty=l2, tfidf__ngram_range=(1, 2); total time= 2.1min\n",
            "[CV] END model__C=0.01, model__penalty=l2, tfidf__ngram_range=(1, 2); total time= 2.2min\n",
            "[CV] END model__C=0.01, model__penalty=l2, tfidf__ngram_range=(1, 2); total time= 2.1min\n",
            "[CV] END model__C=0.01, model__penalty=l2, tfidf__ngram_range=(1, 3); total time= 2.4min\n",
            "[CV] END model__C=0.01, model__penalty=l2, tfidf__ngram_range=(1, 3); total time= 2.3min\n",
            "[CV] END model__C=0.01, model__penalty=l2, tfidf__ngram_range=(1, 3); total time= 2.4min\n",
            "[CV] END model__C=0.1, model__penalty=l1, tfidf__ngram_range=(1, 1); total time= 2.0min\n",
            "[CV] END model__C=0.1, model__penalty=l1, tfidf__ngram_range=(1, 1); total time= 2.0min\n",
            "[CV] END model__C=0.1, model__penalty=l1, tfidf__ngram_range=(1, 1); total time= 2.1min\n",
            "[CV] END model__C=0.1, model__penalty=l1, tfidf__ngram_range=(1, 2); total time= 2.2min\n",
            "[CV] END model__C=0.1, model__penalty=l1, tfidf__ngram_range=(1, 2); total time= 2.2min\n",
            "[CV] END model__C=0.1, model__penalty=l1, tfidf__ngram_range=(1, 2); total time= 2.2min\n",
            "[CV] END model__C=0.1, model__penalty=l1, tfidf__ngram_range=(1, 3); total time= 2.3min\n",
            "[CV] END model__C=0.1, model__penalty=l1, tfidf__ngram_range=(1, 3); total time= 2.4min\n",
            "[CV] END model__C=0.1, model__penalty=l1, tfidf__ngram_range=(1, 3); total time= 2.3min\n",
            "[CV] END model__C=0.1, model__penalty=l2, tfidf__ngram_range=(1, 1); total time= 2.0min\n",
            "[CV] END model__C=0.1, model__penalty=l2, tfidf__ngram_range=(1, 1); total time= 2.0min\n",
            "[CV] END model__C=0.1, model__penalty=l2, tfidf__ngram_range=(1, 1); total time= 2.0min\n",
            "[CV] END model__C=0.1, model__penalty=l2, tfidf__ngram_range=(1, 2); total time= 2.1min\n",
            "[CV] END model__C=0.1, model__penalty=l2, tfidf__ngram_range=(1, 2); total time= 2.1min\n",
            "[CV] END model__C=0.1, model__penalty=l2, tfidf__ngram_range=(1, 2); total time= 2.1min\n",
            "[CV] END model__C=0.1, model__penalty=l2, tfidf__ngram_range=(1, 3); total time= 2.3min\n",
            "[CV] END model__C=0.1, model__penalty=l2, tfidf__ngram_range=(1, 3); total time= 2.3min\n",
            "[CV] END model__C=0.1, model__penalty=l2, tfidf__ngram_range=(1, 3); total time= 2.3min\n",
            "[CV] END model__C=1, model__penalty=l1, tfidf__ngram_range=(1, 1); total time= 2.1min\n",
            "[CV] END model__C=1, model__penalty=l1, tfidf__ngram_range=(1, 1); total time= 2.1min\n",
            "[CV] END model__C=1, model__penalty=l1, tfidf__ngram_range=(1, 1); total time= 2.1min\n",
            "[CV] END model__C=1, model__penalty=l1, tfidf__ngram_range=(1, 2); total time= 2.2min\n",
            "[CV] END model__C=1, model__penalty=l1, tfidf__ngram_range=(1, 2); total time= 2.2min\n",
            "[CV] END model__C=1, model__penalty=l1, tfidf__ngram_range=(1, 2); total time= 2.2min\n",
            "[CV] END model__C=1, model__penalty=l1, tfidf__ngram_range=(1, 3); total time= 2.4min\n",
            "[CV] END model__C=1, model__penalty=l1, tfidf__ngram_range=(1, 3); total time= 2.4min\n",
            "[CV] END model__C=1, model__penalty=l1, tfidf__ngram_range=(1, 3); total time= 2.4min\n",
            "[CV] END model__C=1, model__penalty=l2, tfidf__ngram_range=(1, 1); total time= 2.1min\n",
            "[CV] END model__C=1, model__penalty=l2, tfidf__ngram_range=(1, 1); total time= 2.0min\n",
            "[CV] END model__C=1, model__penalty=l2, tfidf__ngram_range=(1, 1); total time= 2.1min\n",
            "[CV] END model__C=1, model__penalty=l2, tfidf__ngram_range=(1, 2); total time= 2.1min\n",
            "[CV] END model__C=1, model__penalty=l2, tfidf__ngram_range=(1, 2); total time= 2.1min\n",
            "[CV] END model__C=1, model__penalty=l2, tfidf__ngram_range=(1, 2); total time= 2.1min\n",
            "[CV] END model__C=1, model__penalty=l2, tfidf__ngram_range=(1, 3); total time= 2.3min\n",
            "[CV] END model__C=1, model__penalty=l2, tfidf__ngram_range=(1, 3); total time= 2.3min\n",
            "[CV] END model__C=1, model__penalty=l2, tfidf__ngram_range=(1, 3); total time= 2.3min\n",
            "[CV] END model__C=10, model__penalty=l1, tfidf__ngram_range=(1, 1); total time= 2.1min\n",
            "[CV] END model__C=10, model__penalty=l1, tfidf__ngram_range=(1, 1); total time= 2.1min\n",
            "[CV] END model__C=10, model__penalty=l1, tfidf__ngram_range=(1, 1); total time= 2.1min\n",
            "[CV] END model__C=10, model__penalty=l1, tfidf__ngram_range=(1, 2); total time= 2.3min\n",
            "[CV] END model__C=10, model__penalty=l1, tfidf__ngram_range=(1, 2); total time= 2.3min\n",
            "[CV] END model__C=10, model__penalty=l1, tfidf__ngram_range=(1, 2); total time= 2.3min\n",
            "[CV] END model__C=10, model__penalty=l1, tfidf__ngram_range=(1, 3); total time= 2.5min\n",
            "[CV] END model__C=10, model__penalty=l1, tfidf__ngram_range=(1, 3); total time= 2.5min\n",
            "[CV] END model__C=10, model__penalty=l1, tfidf__ngram_range=(1, 3); total time= 2.5min\n",
            "[CV] END model__C=10, model__penalty=l2, tfidf__ngram_range=(1, 1); total time= 2.0min\n",
            "[CV] END model__C=10, model__penalty=l2, tfidf__ngram_range=(1, 1); total time= 1.9min\n",
            "[CV] END model__C=10, model__penalty=l2, tfidf__ngram_range=(1, 1); total time= 2.0min\n",
            "[CV] END model__C=10, model__penalty=l2, tfidf__ngram_range=(1, 2); total time= 2.1min\n",
            "[CV] END model__C=10, model__penalty=l2, tfidf__ngram_range=(1, 2); total time= 2.1min\n",
            "[CV] END model__C=10, model__penalty=l2, tfidf__ngram_range=(1, 2); total time= 2.1min\n",
            "[CV] END model__C=10, model__penalty=l2, tfidf__ngram_range=(1, 3); total time= 2.3min\n",
            "[CV] END model__C=10, model__penalty=l2, tfidf__ngram_range=(1, 3); total time= 2.3min\n",
            "[CV] END model__C=10, model__penalty=l2, tfidf__ngram_range=(1, 3); total time= 2.3min\n",
            "Best parameters found: {'model__C': 0.1, 'model__penalty': 'l2', 'tfidf__ngram_range': (1, 2)}\n",
            "Best F1 score: 0.9266392921068421\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Step 3 - Model fitting, prediction and performance scores**"
      ],
      "metadata": {
        "id": "9Kbnz3W2KSd8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svm_best_model = grid_search.best_estimator_\n",
        "y_svmtest_pred = svm_best_model.predict(x_test)\n",
        "svm_test_f1_score = f1_score(y_test, y_svmtest_pred, average='weighted')\n",
        "svm_test_accuracy = accuracy_score(y_test, y_svmtest_pred)\n",
        "\n",
        "print(\"Test F1 Score:\", svm_test_f1_score)\n",
        "print(\"Test Accuracy:\", svm_test_accuracy)\n",
        "\n",
        "# Predict probabilities for the test set on the best_model\n",
        "y_svmtest_proba = svm_best_model.decision_function(x_test)\n",
        "# Calculate ROC-AUC score for the test sets\n",
        "svmtest_roc_auc = roc_auc_score(np.array(y_test), y_svmtest_proba)\n",
        "print(\"Test ROC-AUC Score:\", svmtest_roc_auc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gm_EvGBlFWKj",
        "outputId": "b65b5c8a-86e1-43fe-b046-3583cf53bdaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test F1 Score: 0.9308350385574501\n",
            "Test Accuracy: 0.9308383574109885\n",
            "Test ROC-AUC Score: 0.9790935985355163\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "F350PSPMKXHm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Logisitc Regression using custom Word2Vec Embeddings**"
      ],
      "metadata": {
        "id": "deBFXOO_KYG5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "from nltk.tokenize import word_tokenize\n",
        "import re\n",
        "\n",
        "\n",
        "\n",
        "# Preprocess and tokenize the documents\n",
        "def preprocess_text(text):\n",
        "    # Basic cleaning - lowercasing, removing non-alphabetic characters\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    tokens = word_tokenize(text)\n",
        "    return tokens\n",
        "\n",
        "# Tokenize each document in your corpus\n",
        "tokenized_documents = [preprocess_text(reviews) for reviews in x_train]\n",
        "\n",
        "# Train a Word2Vec model on the tokenized data\n",
        "w2v_model = Word2Vec(\n",
        "    sentences=tokenized_documents,\n",
        "    vector_size=300,      # Dimensionality of the word vectors\n",
        "    window=5,             # Context window size\n",
        "    min_count=2,          # Ignores words with total frequency lower than this\n",
        "    workers=4,            # Number of worker threads\n",
        "    sg=1                  # Use skip-gram (1) instead of CBOW (0)\n",
        ")\n",
        "\n",
        "# Save the model for future use\n",
        "w2v_model.save(\"custom_word2vec_model.model\")\n",
        "\n",
        "# Access the embedding for a specific word\n",
        "word_vector = w2v_model.wv['car']  # Get the vector for the word 'car'\n",
        "\n",
        "# Check the most similar words to a given word\n",
        "similar_words = w2v_model.wv.most_similar('car', topn=5)\n",
        "print(similar_words)"
      ],
      "metadata": {
        "id": "se_Wpehl3aGs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0709929c-d7b7-4984-9a55-30fb1124db30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('vehicle', 0.7477720379829407), ('vechile', 0.7187308669090271), ('carit', 0.7181493043899536), ('cari', 0.6730164885520935), ('itit', 0.6641161441802979)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "\n",
        "# Custom transformer to average Word2Vec embeddings\n",
        "class Word2VecAveraging(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, w2v_model, vector_size=300):\n",
        "        self.w2v_model = w2v_model\n",
        "        self.vector_size = vector_size\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        return np.array([self._average_word_vectors(text) for text in X])\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def _average_word_vectors(self, text):\n",
        "        words = text.split()  # Tokenize or use a more advanced tokenizer\n",
        "        word_vecs = [self.w2v_model.wv[word] for word in words if word in self.w2v_model.wv]\n",
        "\n",
        "        # If no words in the text are in the Word2Vec vocab, return a zero vector\n",
        "        if not word_vecs:\n",
        "            return np.zeros(self.vector_size)\n",
        "\n",
        "        # Average the word vectors\n",
        "        return np.mean(word_vecs, axis=0)\n",
        "\n",
        "# Assuming `w2v_model` is your trained Word2Vec model\n",
        "w2v_model = Word2Vec.load(\"custom_word2vec_model.model\")\n",
        "\n",
        "# Define the pipeline\n",
        "pipeline = Pipeline([\n",
        "    ('word2vec_avg', Word2VecAveraging(w2v_model=w2v_model, vector_size=300)),\n",
        "    ('model', LogisticRegression(max_iter=500, solver='saga'))\n",
        "])\n",
        "\n",
        "# Define parameter grid for GridSearchCV\n",
        "param_grid = {\n",
        "    'model__C': [0.01, 0.1, 1, 10, 100]  # Regularization strength for logistic regression\n",
        "}\n",
        "\n",
        "# Set up GridSearchCV\n",
        "grid_search = GridSearchCV(\n",
        "    pipeline,\n",
        "    param_grid=param_grid,\n",
        "    scoring='roc_auc',  # Or other metrics such as 'accuracy', 'f1_weighted'\n",
        "    cv=3,               # 3-fold cross-validation\n",
        "    verbose=2,\n",
        ")\n",
        "\n",
        "# Fit GridSearchCV on training data\n",
        "grid_search.fit(x_train, y_train)\n",
        "\n",
        "# Output the best parameters and score\n",
        "print(\"Best parameters found:\", grid_search.best_params_)\n",
        "print(\"Best ROC AUC Score:\", grid_search.best_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKVd4YURPAUc",
        "outputId": "87282148-b6f2-4519-82c3-3d44404d2108"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
            "[CV] END ......................................model__C=0.01; total time=  11.8s\n",
            "[CV] END ......................................model__C=0.01; total time=  11.7s\n",
            "[CV] END ......................................model__C=0.01; total time=  12.6s\n",
            "[CV] END .......................................model__C=0.1; total time=  12.7s\n",
            "[CV] END .......................................model__C=0.1; total time=  12.6s\n",
            "[CV] END .......................................model__C=0.1; total time=  12.8s\n",
            "[CV] END .........................................model__C=1; total time=  16.6s\n",
            "[CV] END .........................................model__C=1; total time=  16.8s\n",
            "[CV] END .........................................model__C=1; total time=  18.9s\n",
            "[CV] END ........................................model__C=10; total time=  43.5s\n",
            "[CV] END ........................................model__C=10; total time=  43.1s\n",
            "[CV] END ........................................model__C=10; total time=  45.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END .......................................model__C=100; total time= 1.4min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END .......................................model__C=100; total time= 1.4min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END .......................................model__C=100; total time= 1.4min\n",
            "Best parameters found: {'model__C': 10}\n",
            "Best ROC AUC Score: 0.9546711668563103\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_best_model = grid_search.best_estimator_\n",
        "y_w2vtest_pred = w2v_best_model.predict(x_test)\n",
        "w2v_test_f1_score = f1_score(y_test, y_w2vtest_pred, average='weighted')\n",
        "w2v_test_accuracy = accuracy_score(y_test, y_w2vtest_pred)\n",
        "\n",
        "print(\"Test F1 Score:\", w2v_test_f1_score)\n",
        "print(\"Test Accuracy:\", w2v_test_accuracy)\n",
        "\n",
        "# Predict probabilities for the test set on the best_model\n",
        "y_w2vtest_proba = w2v_best_model.decision_function(x_test)\n",
        "# Calculate ROC-AUC score for the test sets\n",
        "w2vtest_roc_auc = roc_auc_score(np.array(y_test), y_w2vtest_proba)\n",
        "print(\"Test ROC-AUC Score:\", w2vtest_roc_auc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OzYdrAyVRIp",
        "outputId": "87e2db90-9458-49c2-8fb9-1c81d4cf417a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test F1 Score: 0.9030757745154149\n",
            "Test Accuracy: 0.9030826982140826\n",
            "Test ROC-AUC Score: 0.955628382563383\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qf8_U5GXaNbE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}