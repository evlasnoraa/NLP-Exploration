{"cells":[{"cell_type":"markdown","metadata":{"id":"HWJ8GLXULyY5"},"source":["Process to follow\n","\n","Step 1: Run a field taste with OvR, OvO with TFIDF, then with Word2vec, BERT and then also Truncated SVD. Choose the best performing one for tuning.\n","\n","Step 2: Do same for XGBoost\n","\n","Step 3: NEURAL NETWORKS"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":5072,"status":"ok","timestamp":1733234121167,"user":{"displayName":"Aaron Salve","userId":"08956716697695014521"},"user_tz":0},"id":"wmP4yr527xW-","outputId":"d00f1ed0-97b8-450f-c6a3-c88253ccd46a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting optuna\n","  Downloading optuna-4.1.0-py3-none-any.whl.metadata (16 kB)\n","Collecting alembic>=1.5.0 (from optuna)\n","  Downloading alembic-1.14.0-py3-none-any.whl.metadata (7.4 kB)\n","Collecting colorlog (from optuna)\n","  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.2)\n","Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.36)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.6)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.2)\n","Collecting Mako (from alembic>=1.5.0->optuna)\n","  Downloading Mako-1.3.6-py3-none-any.whl.metadata (2.9 kB)\n","Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n","Downloading optuna-4.1.0-py3-none-any.whl (364 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m364.4/364.4 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading alembic-1.14.0-py3-none-any.whl (233 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.5/233.5 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n","Downloading Mako-1.3.6-py3-none-any.whl (78 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n","Successfully installed Mako-1.3.6 alembic-1.14.0 colorlog-6.9.0 optuna-4.1.0\n"]}],"source":["!pip install optuna"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"g0CpxbnIQoB8","executionInfo":{"status":"ok","timestamp":1733234174794,"user_tz":0,"elapsed":19241,"user":{"displayName":"Aaron Salve","userId":"08956716697695014521"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import nltk\n","import optuna\n","import xgboost as xgb\n","import torch\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics import classification_report, confusion_matrix\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import PorterStemmer\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.pipeline import Pipeline\n","from sklearn.metrics import make_scorer, accuracy_score, f1_score\n","from sklearn.svm import LinearSVC\n","from sklearn.metrics import roc_auc_score\n","from sklearn.multiclass import OneVsRestClassifier\n","from imblearn.over_sampling import SMOTE\n","from sklearn.svm import SVC\n","from sklearn.multiclass import OneVsOneClassifier\n","from gensim.models import Word2Vec\n","from xgboost import XGBClassifier\n","from transformers import DistilBertTokenizer, DistilBertModel\n","from sklearn.preprocessing import LabelEncoder"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":836,"status":"ok","timestamp":1733234178325,"user":{"displayName":"Aaron Salve","userId":"08956716697695014521"},"user_tz":0},"id":"s98p5q0qTu1g","outputId":"8a1995da-af80-42ac-8992-2319d337d248"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":3}],"source":["nltk.download('stopwords')\n","nltk.download('punkt')\n","nltk.download('punkt_tab')"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2719,"status":"ok","timestamp":1733234183843,"user":{"displayName":"Aaron Salve","userId":"08956716697695014521"},"user_tz":0},"id":"bTZ4Era-T6HS","outputId":"208bc05f-4f81-471b-969b-63c6b7800ab8"},"outputs":[{"output_type":"stream","name":"stdout","text":["                                              Review  Rating\n","0  I love this car.\\nGas mileage, suspension, and...       5\n","1  I purchased my 2013 ILX from the dealer used w...       5\n","2  I recently purchased a 2013 ILX with the Tech ...       4\n","3  We bought our ILX used and have been incredibl...       4\n","4  In April of 2015 we were in need of another ca...       5\n"]}],"source":["# Load your Excel data into a pandas DataFrame\n","df = pd.read_csv('Review.csv')\n","\n","# Select only the 'review' and 'rating' columns\n","df_filtered = df[['Review', 'Rating']]\n","\n","df_filtered = df_filtered[df_filtered['Rating'] != 0]\n","\n","# Removing nan values\n","df_filtered.dropna(inplace=True)\n","\n","# Display the first few rows of the final DataFrame\n","print(df_filtered.head())"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"fl2_2oz-0nAZ","executionInfo":{"status":"ok","timestamp":1733234183843,"user_tz":0,"elapsed":2,"user":{"displayName":"Aaron Salve","userId":"08956716697695014521"}}},"outputs":[],"source":["def review_cleaner(review):\n","  stopwords = nltk.corpus.stopwords.words(\"english\")\n","  porter = PorterStemmer()\n","  # Make sure the reviews are not case sensitive\n","  review = review.lower()\n","  # Tokenize the words from the review\n","  words = nltk.word_tokenize(review)\n","  # Stemming and stopwords removal\n","  processed_words = [porter.stem(word) for word in words if word not in stopwords]\n","  # Join back to a single string\n","  return ' '.join(processed_words)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":209,"status":"ok","timestamp":1733234187340,"user":{"displayName":"Aaron Salve","userId":"08956716697695014521"},"user_tz":0},"id":"bl2F8ibqs4vr","outputId":"26aec4a7-e32b-4de0-dfc9-f89f4e3dc901"},"outputs":[{"output_type":"stream","name":"stdout","text":["                                              Review  Rating\n","0  Our 2008 Town & Country shuts off while drivin...       1\n","1  I purchased this new in 2012 and paid cash for...       1\n","2  Update:  12/28/2019 - GPS/INFOTAINMENT SCREEN ...       1\n","3  I thought I was getting a good deal. A mint fu...       1\n","4  I have had a rattle in my new VW atlas after t...       1\n"]}],"source":["# Since Rating 1 has the least frequency, we use the same number for all other classes.\n","val = df_filtered['Rating'].value_counts()[1]\n","\n","# Balancing class frequencies\n","df_rating_1 = df_filtered[df_filtered['Rating'] == 1].sample(n=val, random_state=1)\n","df_rating_2 = df_filtered[df_filtered['Rating'] == 2].sample(n=val, random_state=1)\n","df_rating_3 = df_filtered[df_filtered['Rating'] == 3].sample(n=val, random_state=1)\n","df_rating_4 = df_filtered[df_filtered['Rating'] == 4].sample(n=val, random_state=1)\n","df_rating_5 = df_filtered[df_filtered['Rating'] == 5].sample(n=val, random_state=1)\n","\n","# Combine the samples into a single DataFrame\n","balanced_df = pd.concat([df_rating_1, df_rating_2, df_rating_3, df_rating_4, df_rating_5])\n","\n","# Reset the index for neatness\n","balanced_df.reset_index(drop=True, inplace=True)\n","\n","# Removing nan values\n","balanced_df.dropna(inplace=True)\n","\n","# Display the first few rows of the final DataFrame\n","print(balanced_df.head())"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1733234187536,"user":{"displayName":"Aaron Salve","userId":"08956716697695014521"},"user_tz":0},"id":"mmtOuaig0VMs","outputId":"ddc147e3-0dc4-44a4-db4f-f5adee62ffdb"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(54950, 2)"]},"metadata":{},"execution_count":7}],"source":["balanced_df.shape"]},{"cell_type":"markdown","metadata":{"id":"k-hLQXu2zSpL"},"source":["#**Algorithms with T-IDF Vectors**"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"MwcMl_eA0aKY","executionInfo":{"status":"ok","timestamp":1733234435112,"user_tz":0,"elapsed":125286,"user":{"displayName":"Aaron Salve","userId":"08956716697695014521"}}},"outputs":[],"source":["X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(balanced_df['Review'], balanced_df['Rating'], stratify =balanced_df['Rating'], shuffle = True, test_size=0.2, random_state=3)\n","X_train_1, X_val_1, y_train_1, y_val_1 = train_test_split(X_train_1, y_train_1, stratify = y_train_1, shuffle = True, test_size=0.25, random_state=3)\n","\n","tfidf2 = TfidfVectorizer(preprocessor=review_cleaner, max_features = 7000, ngram_range = (1, 2))\n","X_train_tfidf_2 = tfidf2.fit_transform(X_train_1)\n","X_test_tfidf_2 = tfidf2.transform(X_test_1)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":160745,"status":"ok","timestamp":1733234595855,"user":{"displayName":"Aaron Salve","userId":"08956716697695014521"},"user_tz":0},"id":"440ZR0NZnlu0","outputId":"73318706-1cda-4826-b7f5-477ed7e65de7"},"outputs":[{"output_type":"stream","name":"stdout","text":["0.8055264277807354\n","0.8055264277807354\n","              precision    recall  f1-score   support\n","\n","           1       0.52      0.57      0.55      2198\n","           2       0.37      0.35      0.36      2198\n","           3       0.39      0.37      0.38      2198\n","           4       0.46      0.44      0.45      2198\n","           5       0.55      0.59      0.57      2198\n","\n","    accuracy                           0.46     10990\n","   macro avg       0.46      0.46      0.46     10990\n","weighted avg       0.46      0.46      0.46     10990\n","\n"]}],"source":["lr = OneVsRestClassifier(LogisticRegression(max_iter=200, class_weight='balanced', solver='saga', penalty = 'elasticnet', C = 2, l1_ratio = 0.22405730364701912))\n","lr.fit(X_train_tfidf_2, y_train_1)\n","y_pred_lr = lr.predict(X_test_tfidf_2)\n","y_pred_probs_lr = lr.predict_proba(X_test_tfidf_2)\n","\n","print(roc_auc_score(y_test_1, y_pred_probs_lr, multi_class='ovr'))\n","print(roc_auc_score(y_test_1, y_pred_probs_lr, average='macro', multi_class='ovr'))\n","print(classification_report(y_test_1, y_pred_lr))\n"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":353492,"status":"ok","timestamp":1733234949341,"user":{"displayName":"Aaron Salve","userId":"08956716697695014521"},"user_tz":0},"id":"jq75rxlcpGsx","outputId":"6388852e-865b-4a68-a9ec-dcad28368051"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n","  warnings.warn(\n"]}],"source":["svc = OneVsOneClassifier(SVC(class_weight = 'balanced', max_iter = 1000))\n","svc.fit(X_train_tfidf_2, y_train_1)\n","y_pred_svc = svc.predict(X_test_tfidf_2)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1733234949341,"user":{"displayName":"Aaron Salve","userId":"08956716697695014521"},"user_tz":0},"id":"1hcCPxh_QyY3","outputId":"a631e48f-9d74-4d81-f763-5a4a1ba3e734"},"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           1       0.45      0.55      0.49      2198\n","           2       0.34      0.27      0.30      2198\n","           3       0.33      0.30      0.31      2198\n","           4       0.40      0.35      0.37      2198\n","           5       0.49      0.60      0.54      2198\n","\n","    accuracy                           0.41     10990\n","   macro avg       0.40      0.41      0.41     10990\n","weighted avg       0.40      0.41      0.41     10990\n","\n"]}],"source":["print(classification_report(y_test_1, y_pred_svc))"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":345771,"status":"ok","timestamp":1733235295109,"user":{"displayName":"Aaron Salve","userId":"08956716697695014521"},"user_tz":0},"id":"Tp7EGgUIEjwX","outputId":"97b0e7d6-bdb0-4e0d-c5da-fcac84b2a35b"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [14:09:09] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           1       0.52      0.58      0.55      2198\n","           2       0.38      0.37      0.37      2198\n","           3       0.39      0.32      0.36      2198\n","           4       0.45      0.41      0.43      2198\n","           5       0.52      0.61      0.56      2198\n","\n","    accuracy                           0.46     10990\n","   macro avg       0.45      0.46      0.45     10990\n","weighted avg       0.45      0.46      0.45     10990\n","\n"]}],"source":["xgb_model = XGBClassifier(\n","    objective='multi:softprob',\n","    num_class=5,\n","    eval_metric='mlogloss',\n","    use_label_encoder=False,\n","    random_state=42\n",")\n","\n","le = LabelEncoder()\n","y_train_xgb = le.fit_transform(y_train_1)\n","\n","xgb_model.fit(X_train_tfidf_2, y_train_xgb)\n","y_pred_xgb = xgb_model.predict(X_test_tfidf_2)\n","y_pred_xgb = le.inverse_transform(y_pred_xgb)\n","print(classification_report(y_test_1, y_pred_xgb))"]},{"cell_type":"markdown","metadata":{"id":"goFXUvOUL6E5"},"source":["#**Algorithms with Word2Vec Embeddings**"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"ZAgyBBV9C-qx","executionInfo":{"status":"ok","timestamp":1733235809727,"user_tz":0,"elapsed":514621,"user":{"displayName":"Aaron Salve","userId":"08956716697695014521"}}},"outputs":[],"source":["# Tokenize your reviews for Word2Vec training\n","def tokenize_reviews(reviews):\n","    return [nltk.word_tokenize(review.lower()) for review in reviews]\n","\n","# Tokenize the reviews\n","tokenized_reviews = tokenize_reviews(balanced_df['Review'])\n","\n","# Train a Word2Vec model on your dataset\n","word2vec_model = Word2Vec(\n","    sentences=tokenized_reviews,\n","    vector_size=300,   # Embedding size\n","    window=5,          # Context window size\n","    min_count=2,       # Ignore words with frequency < 2\n","    sg=1,              # Skip-gram model\n","    epochs=10          # Training iterations\n",")\n","\n","# Save the model for later use\n","word2vec_model.save(\"custom_word2vec.model\")\n","\n","# Generate averaged Word2Vec embeddings for each review\n","def get_avg_word2vec_embeddings(reviews, model):\n","    embeddings = []\n","    for review in tokenize_reviews(reviews):\n","        vectors = [model.wv[word] for word in review if word in model.wv]\n","        if vectors:\n","            avg_vector = np.mean(vectors, axis=0)\n","        else:\n","            avg_vector = np.zeros(model.vector_size)\n","        embeddings.append(avg_vector)\n","    return np.array(embeddings)\n","\n","# Generate embeddings for train and test\n","X_train_word2vec = get_avg_word2vec_embeddings(X_train_1, word2vec_model)\n","X_test_word2vec = get_avg_word2vec_embeddings(X_test_1, word2vec_model)"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5XCrvEIiVj-8","outputId":"81103e76-6590-408c-81c7-0a95b4ff55f5","executionInfo":{"status":"ok","timestamp":1733235858813,"user_tz":0,"elapsed":49089,"user":{"displayName":"Aaron Salve","userId":"08956716697695014521"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["0.8018057920965458\n","0.8018057920965458\n","              precision    recall  f1-score   support\n","\n","           1       0.51      0.62      0.56      2198\n","           2       0.38      0.33      0.35      2198\n","           3       0.39      0.35      0.37      2198\n","           4       0.45      0.44      0.45      2198\n","           5       0.57      0.60      0.59      2198\n","\n","    accuracy                           0.47     10990\n","   macro avg       0.46      0.47      0.46     10990\n","weighted avg       0.46      0.47      0.46     10990\n","\n"]}],"source":["lr_w2v = OneVsRestClassifier(LogisticRegression(max_iter=200, class_weight='balanced', solver='saga', penalty = 'elasticnet', C = 1, l1_ratio = 0.2))\n","lr_w2v.fit(X_train_word2vec, y_train_1)\n","y_pred_lrw2v = lr_w2v.predict(X_test_word2vec)\n","y_pred_probs_lrw2v = lr_w2v.predict_proba(X_test_word2vec)\n","\n","print(roc_auc_score(y_test_1, y_pred_probs_lrw2v, multi_class='ovr'))\n","print(roc_auc_score(y_test_1, y_pred_probs_lrw2v, average='macro', multi_class='ovr'))\n","print(classification_report(y_test_1, y_pred_lrw2v))"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":539296,"status":"ok","timestamp":1733236398106,"user":{"displayName":"Aaron Salve","userId":"08956716697695014521"},"user_tz":0},"id":"eFT7q47cWUyS","outputId":"ae3a7917-1dca-4bd0-c965-2802c56a2fbb"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           1       0.55      0.46      0.50      2198\n","           2       0.37      0.36      0.36      2198\n","           3       0.38      0.46      0.42      2198\n","           4       0.42      0.41      0.42      2198\n","           5       0.54      0.56      0.55      2198\n","\n","    accuracy                           0.45     10990\n","   macro avg       0.45      0.45      0.45     10990\n","weighted avg       0.45      0.45      0.45     10990\n","\n"]}],"source":["from sklearn.preprocessing import StandardScaler\n","\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train_word2vec)\n","X_test_scaled = scaler.transform(X_test_word2vec)\n","\n","svc_w2v = OneVsOneClassifier(SVC(class_weight = 'balanced', max_iter = 3000, C = 1))\n","svc_w2v.fit(X_train_scaled, y_train_1)\n","y_pred_svcw2v = svc_w2v.predict(X_test_scaled)\n","print(classification_report(y_test_1, y_pred_svcw2v))"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":99272,"status":"ok","timestamp":1733236497372,"user":{"displayName":"Aaron Salve","userId":"08956716697695014521"},"user_tz":0},"id":"hu1VvAzZU55i","outputId":"55207c38-0849-4a24-c04e-97438d967091"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [14:33:19] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           1       0.52      0.58      0.55      2198\n","           2       0.39      0.37      0.38      2198\n","           3       0.36      0.33      0.35      2198\n","           4       0.44      0.44      0.44      2198\n","           5       0.56      0.55      0.56      2198\n","\n","    accuracy                           0.46     10990\n","   macro avg       0.45      0.46      0.45     10990\n","weighted avg       0.45      0.46      0.45     10990\n","\n"]}],"source":["xgb_w2v = XGBClassifier(\n","    objective='multi:softprob',\n","    num_class=5,\n","    eval_metric='mlogloss',\n","    use_label_encoder=False,\n","    random_state=42\n",")\n","\n","xgb_w2v.fit(X_train_word2vec, y_train_xgb)\n","y_pred_xgbw2v = xgb_w2v.predict(X_test_word2vec)\n","y_pred_xgbw2v = le.inverse_transform(y_pred_xgbw2v)\n","print(classification_report(y_test_1, y_pred_xgbw2v))"]},{"cell_type":"markdown","metadata":{"id":"DcgfRUeqL9nN"},"source":["#**Alogorithms with BERT Embeddings**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":7222,"status":"ok","timestamp":1732383798060,"user":{"displayName":"Aaron Salve","userId":"06603791010460543875"},"user_tz":0},"id":"MlIWWczIvz1Y","outputId":"d8bfccf0-f5df-4c12-db1b-5d9dcb143daa"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n","Collecting onnxruntime\n","  Downloading onnxruntime-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n","Collecting onnx\n","  Downloading onnx-1.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n","Collecting coloredlogs (from onnxruntime)\n","  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.3.25)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (4.25.5)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.13.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n","Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n","  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n","Downloading onnxruntime-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m81.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading onnx-1.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m102.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: onnx, humanfriendly, coloredlogs, onnxruntime\n","Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnx-1.17.0 onnxruntime-1.20.1\n"]}],"source":["# Install required libraries\n","!pip install transformers onnxruntime onnx\n","\n","# Import necessary libraries\n","import torch\n","import onnxruntime as ort\n","\n","\n","from sklearn.preprocessing import LabelBinarizer\n","from sklearn.metrics import classification_report, accuracy_score\n","from transformers import BertTokenizer, BertModel, pipeline"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["b8a1f6b4c04841e4bfd4c3a12fd1f041","ed50c6e20d6d4cdc832c130c847b4ed7","dbc53083d53f49eca734ac5b29fdd1c8","c125252405a54c0c8e31e6ff9f8ef97f","8f823e1ffb194cc39db5db6fbe0fb607","f1087b0da431424c97aa3835e40bc94d","9c2b5a2cb84f448db2020773f1790719","a4fa70ce328149a7926a2d9e48f9b63f","c50c812f8d674fc681816f603f7f19f3","f1148fa12cfc4b0abdd293c3a0af87fb","1e1c15187a10424e85bdd1d3b1d79fb8","16ea22bbbbdf40b999ba26ec821890d1","e11f977dd30d4f939c316f60d0a4d2e9","692a574411824cf39d8b5e1455948a2f","683f51b4daa2478aa016e3e5aeca2252","4bd4fe8df1fd48fc8b11dc9595db60b1","517e12ef1d7c4dae8730ab8241675ec1","10f1b660eec74c6984c83f01ec5fae44","67295b66764d4506af2cb96a9da75924","c499a1f224824bd89ed654ab6d0e2462","3e27a859fffc4e26aba9b9570cb4d08d","6e1dccae645341259e7e0d5ac252803f","8c11dfdac7014a298669900bdba9b520","0dbc70d0e9394460ad7b0c07681db0fb","f88ba5b8333547ffb7cf6f6ba70e73fd","4cab20ac13874320b4be7176ff170718","e2d74b97e6214b648d96889dd51c1fc4","f966dc370e4746b681d3b44d65eb4279","c6fe571ce2e048bbb127a7c16bddba35","53699bdef4e54d7dae26ba0bb1eb93ae","3739e394957d4bdfbcec9dbea35e6df9","ed27da71341d4374845c64aeed084fee","a5c7820c21274dff887d7d9b3e1396e9","fe6244f7ffc940ad80fba444df2f05ee","136faf686c3c4c25a3421aea0b2dad97","ccf90499ee4341d1878735ac512765fb","4c19069e19db40248fc6c64d0461bd49","beef2e942bab404a92bd11a92b9f8500","af9a146eaad8459b97ddfa3b3c93f806","c535c4852bc14902a99fcf34d1b7259e","86bb213084bd40b5926c9bafd4aceae2","7a358684513b487db5be6c882a08160e","a56c213ab58943b3b5ea8b38e6181762","6f3bf004ca884ab3a3efe8f86b9677de","a0fb39408c3c4c22bc017437f96d0e95","3d37a1518e1744afa151d98ba4edd832","733b149239714b6994bba744598a8f11","9e39a4d032864d37866d6f1d0b00179a","8cbd5f957a72480cbfaf6673dc1aeaef","1d2f104abdef44acbcf4d4f8afc74f74","be391209f44643abab52ced5f7b35c22","86be4714caf54e19b517443539cc026a","e5b4abfe6592433c9985a15b19f0ef21","28c05d1fb53b48388dc31ad814cad99c","3396fab10708438ead073b497be4f8cc"]},"executionInfo":{"elapsed":2539101,"status":"ok","timestamp":1732386666633,"user":{"displayName":"Aaron Salve","userId":"06603791010460543875"},"user_tz":0},"id":"eyCbDwgWukKC","outputId":"9c70c7d0-4cf1-4ef9-de20-16b98193ac38"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cuda\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b8a1f6b4c04841e4bfd4c3a12fd1f041","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"16ea22bbbbdf40b999ba26ec821890d1","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8c11dfdac7014a298669900bdba9b520","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fe6244f7ffc940ad80fba444df2f05ee","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a0fb39408c3c4c22bc017437f96d0e95","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Generating BERT embeddings for training data...\n","Generating BERT embeddings for testing data...\n","Training One-vs-Rest Logistic Regression...\n","Logistic Regression Evaluation:\n","              precision    recall  f1-score   support\n","\n","           1       0.11      0.86      0.19      2250\n","           2       0.38      0.06      0.10      3538\n","           3       0.45      0.07      0.12      6296\n","           4       0.63      0.68      0.65     28688\n","           5       0.65      0.30      0.41     19005\n","\n","    accuracy                           0.47     59777\n","   macro avg       0.44      0.39      0.30     59777\n","weighted avg       0.58      0.47      0.47     59777\n","\n","Training XGBoost Classifier...\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:28:19] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n"]},{"name":"stdout","output_type":"stream","text":["XGBoost Evaluation:\n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00         1\n","           1       0.42      0.27      0.33      2249\n","           2       0.33      0.23      0.27      3538\n","           3       0.37      0.28      0.32      6296\n","           4       0.59      0.77      0.67     28688\n","           5       0.58      0.41      0.48     19005\n","\n","    accuracy                           0.55     59777\n","   macro avg       0.38      0.33      0.35     59777\n","weighted avg       0.54      0.55      0.54     59777\n","\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]}],"source":["# Check GPU availability\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print(f\"Using device: {device}\")\n","\n","# Load your data (replace 'data.csv' with your dataset path)\n","# Assuming the DataFrame has 'reviews' (text) and 'ratings' (integer between 1 and 5)\n","new_df = pd.read_csv('Review.csv')  # Replace with your data file\n","new_df = new_df.dropna()  # Ensure no missing values\n","\n","# Train-test split\n","X = new_df['Review'].tolist()\n","y = new_df['Rating'].tolist()\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Convert y to one-hot for One-vs-Rest classifier\n","lb = LabelBinarizer()\n","y_train_ovr = lb.fit_transform(y_train)\n","y_test_ovr = lb.transform(y_test)\n","\n","# Load BERT model and tokenizer\n","model_name = \"bert-base-uncased\"\n","tokenizer = BertTokenizer.from_pretrained(model_name)\n","bert_model = BertModel.from_pretrained(model_name).to(device)\n","\n","# Function to generate BERT embeddings\n","def get_bert_embeddings(texts, batch_size=512):\n","    \"\"\"Generate BERT embeddings for a list of texts.\"\"\"\n","    bert_model.eval()\n","    embeddings = []\n","    for i in range(0, len(texts), batch_size):\n","        batch = texts[i:i + batch_size]\n","        tokens = tokenizer(batch, padding=True, truncation=True, return_tensors=\"pt\", max_length=512).to(device)\n","        with torch.no_grad():\n","            outputs = bert_model(**tokens)\n","        # Use [CLS] token embeddings\n","        cls_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n","        embeddings.extend(cls_embeddings)\n","    return np.array(embeddings)\n","\n","# Generate embeddings for training and testing\n","print(\"Generating BERT embeddings for training data...\")\n","X_train_embeddings = get_bert_embeddings(X_train)\n","\n","print(\"Generating BERT embeddings for testing data...\")\n","X_test_embeddings = get_bert_embeddings(X_test)\n","\n","# Logistic Regression (One-vs-Rest)\n","print(\"Training One-vs-Rest Logistic Regression...\")\n","ovr_clf = OneVsRestClassifier(LogisticRegression(max_iter=1000, random_state=42))\n","ovr_clf.fit(X_train_embeddings, y_train_ovr)\n","\n","# Predict and evaluate Logistic Regression\n","y_pred_ovr = ovr_clf.predict(X_test_embeddings)\n","print(\"Logistic Regression Evaluation:\")\n","print(classification_report(lb.inverse_transform(y_test_ovr), lb.inverse_transform(y_pred_ovr)))\n","\n","# XGBoost Classifier\n","print(\"Training XGBoost Classifier...\")\n","xgb_clf = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n","\n","le = LabelEncoder()\n","y_train_xgb = le.fit_transform(y_train)\n","\n","xgb_clf.fit(X_train_embeddings, y_train_xgb)\n","\n","y_pred_xgb = xgb_clf.predict(X_test_embeddings)\n","y_pred_xgb = le.inverse_transform(y_pred_xgb)\n","\n","print(\"XGBoost Evaluation:\")\n","print(classification_report(y_test, y_pred_xgb))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":520620,"status":"ok","timestamp":1732388309126,"user":{"displayName":"Aaron Salve","userId":"06603791010460543875"},"user_tz":0},"id":"XFrYA4szWC_i","outputId":"9a7bc312-a9ec-4a79-aa6b-161684597dd9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Generating BERT embeddings for training data...\n","Generating BERT embeddings for testing data...\n","Training One-vs-Rest Logistic Regression...\n","Logistic Regression Evaluation:\n","              precision    recall  f1-score   support\n","\n","           1       0.28      0.92      0.42      2243\n","           2       0.48      0.10      0.16      2190\n","           3       0.49      0.11      0.18      2234\n","           4       0.53      0.29      0.38      2156\n","           5       0.63      0.41      0.50      2167\n","\n","    accuracy                           0.37     10990\n","   macro avg       0.48      0.36      0.33     10990\n","weighted avg       0.48      0.37      0.33     10990\n","\n","Training XGBoost Classifier...\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:57:25] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n"]},{"name":"stdout","output_type":"stream","text":["XGBoost Evaluation:\n","              precision    recall  f1-score   support\n","\n","           1       0.51      0.54      0.53      2243\n","           2       0.37      0.37      0.37      2190\n","           3       0.38      0.34      0.36      2234\n","           4       0.44      0.43      0.44      2156\n","           5       0.54      0.57      0.56      2167\n","\n","    accuracy                           0.45     10990\n","   macro avg       0.45      0.45      0.45     10990\n","weighted avg       0.45      0.45      0.45     10990\n","\n"]}],"source":["# Train-test split\n","X = balanced_df['Review'].tolist()\n","y = balanced_df['Rating'].tolist()\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Convert y to one-hot for One-vs-Rest classifier\n","lb = LabelBinarizer()\n","y_train_ovr = lb.fit_transform(y_train)\n","y_test_ovr = lb.transform(y_test)\n","\n","# Load BERT model and tokenizer\n","model_name = \"bert-base-uncased\"\n","tokenizer = BertTokenizer.from_pretrained(model_name)\n","bert_model = BertModel.from_pretrained(model_name).to(device)\n","\n","# Function to generate BERT embeddings\n","def get_bert_embeddings(texts, batch_size=512):\n","    \"\"\"Generate BERT embeddings for a list of texts.\"\"\"\n","    bert_model.eval()\n","    embeddings = []\n","    for i in range(0, len(texts), batch_size):\n","        batch = texts[i:i + batch_size]\n","        tokens = tokenizer(batch, padding=True, truncation=True, return_tensors=\"pt\", max_length=512).to(device)\n","        with torch.no_grad():\n","            outputs = bert_model(**tokens)\n","        # Use [CLS] token embeddings\n","        cls_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n","        embeddings.extend(cls_embeddings)\n","    return np.array(embeddings)\n","\n","# Generate embeddings for training and testing\n","print(\"Generating BERT embeddings for training data...\")\n","X_train_embeddings = get_bert_embeddings(X_train)\n","\n","print(\"Generating BERT embeddings for testing data...\")\n","X_test_embeddings = get_bert_embeddings(X_test)\n","\n","# Logistic Regression (One-vs-Rest)\n","print(\"Training One-vs-Rest Logistic Regression...\")\n","ovr_clf = OneVsRestClassifier(LogisticRegression(max_iter=1000, random_state=42))\n","ovr_clf.fit(X_train_embeddings, y_train_ovr)\n","\n","# Predict and evaluate Logistic Regression\n","y_pred_ovr = ovr_clf.predict(X_test_embeddings)\n","print(\"Logistic Regression Evaluation:\")\n","print(classification_report(lb.inverse_transform(y_test_ovr), lb.inverse_transform(y_pred_ovr)))\n","\n","# XGBoost Classifier\n","print(\"Training XGBoost Classifier...\")\n","xgb_clf = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n","\n","le = LabelEncoder()\n","y_train_xgb = le.fit_transform(y_train)\n","\n","xgb_clf.fit(X_train_embeddings, y_train_xgb)\n","\n","y_pred_xgb = xgb_clf.predict(X_test_embeddings)\n","y_pred_xgb = le.inverse_transform(y_pred_xgb)\n","\n","print(\"XGBoost Evaluation:\")\n","print(classification_report(y_test, y_pred_xgb))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":409631,"status":"ok","timestamp":1732389802898,"user":{"displayName":"Aaron Salve","userId":"06603791010460543875"},"user_tz":0},"id":"LTaQnWGLcqaK","outputId":"9d67d802-f41d-4775-f91a-7871927f8a74"},"outputs":[{"name":"stdout","output_type":"stream","text":["Generating BERT embeddings for training data...\n","Generating BERT embeddings for testing data...\n","Training One-vs-Rest Logistic Regression...\n","Logistic Regression Evaluation:\n","              precision    recall  f1-score   support\n","\n","           1       0.41      0.82      0.54      2228\n","           2       0.59      0.30      0.40      2159\n","           4       0.58      0.45      0.51      2188\n","           5       0.66      0.45      0.53      2217\n","\n","    accuracy                           0.51      8792\n","   macro avg       0.56      0.50      0.50      8792\n","weighted avg       0.56      0.51      0.50      8792\n","\n","Training XGBoost Classifier...\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [19:22:36] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n"]},{"name":"stdout","output_type":"stream","text":["XGBoost Evaluation:\n","              precision    recall  f1-score   support\n","\n","           1       0.57      0.58      0.57      2228\n","           2       0.51      0.51      0.51      2159\n","           4       0.52      0.50      0.51      2188\n","           5       0.58      0.59      0.59      2217\n","\n","    accuracy                           0.55      8792\n","   macro avg       0.54      0.54      0.54      8792\n","weighted avg       0.54      0.55      0.54      8792\n","\n"]}],"source":["# Train-test split\n","balanced_df = balanced_df[balanced_df['Rating'] != 3]\n","\n","X = balanced_df['Review'].tolist()\n","y = balanced_df['Rating'].tolist()\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Convert y to one-hot for One-vs-Rest classifier\n","lb = LabelBinarizer()\n","y_train_ovr = lb.fit_transform(y_train)\n","y_test_ovr = lb.transform(y_test)\n","\n","# Load BERT model and tokenizer\n","model_name = \"bert-base-uncased\"\n","tokenizer = BertTokenizer.from_pretrained(model_name)\n","bert_model = BertModel.from_pretrained(model_name).to(device)\n","\n","# Function to generate BERT embeddings\n","def get_bert_embeddings(texts, batch_size=512):\n","    \"\"\"Generate BERT embeddings for a list of texts.\"\"\"\n","    bert_model.eval()\n","    embeddings = []\n","    for i in range(0, len(texts), batch_size):\n","        batch = texts[i:i + batch_size]\n","        tokens = tokenizer(batch, padding=True, truncation=True, return_tensors=\"pt\", max_length=512).to(device)\n","        with torch.no_grad():\n","            outputs = bert_model(**tokens)\n","        # Use [CLS] token embeddings\n","        cls_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n","        embeddings.extend(cls_embeddings)\n","    return np.array(embeddings)\n","\n","# Generate embeddings for training and testing\n","print(\"Generating BERT embeddings for training data...\")\n","X_train_embeddings = get_bert_embeddings(X_train)\n","\n","print(\"Generating BERT embeddings for testing data...\")\n","X_test_embeddings = get_bert_embeddings(X_test)\n","\n","# Logistic Regression (One-vs-Rest)\n","print(\"Training One-vs-Rest Logistic Regression...\")\n","ovr_clf = OneVsRestClassifier(LogisticRegression(max_iter=1000, random_state=42))\n","ovr_clf.fit(X_train_embeddings, y_train_ovr)\n","\n","# Predict and evaluate Logistic Regression\n","y_pred_ovr = ovr_clf.predict(X_test_embeddings)\n","print(\"Logistic Regression Evaluation:\")\n","print(classification_report(lb.inverse_transform(y_test_ovr), lb.inverse_transform(y_pred_ovr)))\n","\n","# XGBoost Classifier\n","print(\"Training XGBoost Classifier...\")\n","xgb_clf = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n","\n","le = LabelEncoder()\n","y_train_xgb = le.fit_transform(y_train)\n","\n","xgb_clf.fit(X_train_embeddings, y_train_xgb)\n","\n","y_pred_xgb = xgb_clf.predict(X_test_embeddings)\n","y_pred_xgb = le.inverse_transform(y_pred_xgb)\n","\n","print(\"XGBoost Evaluation:\")\n","print(classification_report(y_test, y_pred_xgb))"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0dbc70d0e9394460ad7b0c07681db0fb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f966dc370e4746b681d3b44d65eb4279","placeholder":"​","style":"IPY_MODEL_c6fe571ce2e048bbb127a7c16bddba35","value":"tokenizer.json: 100%"}},"10f1b660eec74c6984c83f01ec5fae44":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"136faf686c3c4c25a3421aea0b2dad97":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_af9a146eaad8459b97ddfa3b3c93f806","placeholder":"​","style":"IPY_MODEL_c535c4852bc14902a99fcf34d1b7259e","value":"config.json: 100%"}},"16ea22bbbbdf40b999ba26ec821890d1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e11f977dd30d4f939c316f60d0a4d2e9","IPY_MODEL_692a574411824cf39d8b5e1455948a2f","IPY_MODEL_683f51b4daa2478aa016e3e5aeca2252"],"layout":"IPY_MODEL_4bd4fe8df1fd48fc8b11dc9595db60b1"}},"1d2f104abdef44acbcf4d4f8afc74f74":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e1c15187a10424e85bdd1d3b1d79fb8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"28c05d1fb53b48388dc31ad814cad99c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3396fab10708438ead073b497be4f8cc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3739e394957d4bdfbcec9dbea35e6df9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3d37a1518e1744afa151d98ba4edd832":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1d2f104abdef44acbcf4d4f8afc74f74","placeholder":"​","style":"IPY_MODEL_be391209f44643abab52ced5f7b35c22","value":"model.safetensors: 100%"}},"3e27a859fffc4e26aba9b9570cb4d08d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4bd4fe8df1fd48fc8b11dc9595db60b1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c19069e19db40248fc6c64d0461bd49":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a56c213ab58943b3b5ea8b38e6181762","placeholder":"​","style":"IPY_MODEL_6f3bf004ca884ab3a3efe8f86b9677de","value":" 570/570 [00:00&lt;00:00, 53.1kB/s]"}},"4cab20ac13874320b4be7176ff170718":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ed27da71341d4374845c64aeed084fee","placeholder":"​","style":"IPY_MODEL_a5c7820c21274dff887d7d9b3e1396e9","value":" 466k/466k [00:00&lt;00:00, 677kB/s]"}},"517e12ef1d7c4dae8730ab8241675ec1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"53699bdef4e54d7dae26ba0bb1eb93ae":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"67295b66764d4506af2cb96a9da75924":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"683f51b4daa2478aa016e3e5aeca2252":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e27a859fffc4e26aba9b9570cb4d08d","placeholder":"​","style":"IPY_MODEL_6e1dccae645341259e7e0d5ac252803f","value":" 232k/232k [00:00&lt;00:00, 12.2MB/s]"}},"692a574411824cf39d8b5e1455948a2f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_67295b66764d4506af2cb96a9da75924","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c499a1f224824bd89ed654ab6d0e2462","value":231508}},"6e1dccae645341259e7e0d5ac252803f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6f3bf004ca884ab3a3efe8f86b9677de":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"733b149239714b6994bba744598a8f11":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_86be4714caf54e19b517443539cc026a","max":440449768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e5b4abfe6592433c9985a15b19f0ef21","value":440449768}},"7a358684513b487db5be6c882a08160e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"86bb213084bd40b5926c9bafd4aceae2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"86be4714caf54e19b517443539cc026a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c11dfdac7014a298669900bdba9b520":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0dbc70d0e9394460ad7b0c07681db0fb","IPY_MODEL_f88ba5b8333547ffb7cf6f6ba70e73fd","IPY_MODEL_4cab20ac13874320b4be7176ff170718"],"layout":"IPY_MODEL_e2d74b97e6214b648d96889dd51c1fc4"}},"8cbd5f957a72480cbfaf6673dc1aeaef":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f823e1ffb194cc39db5db6fbe0fb607":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c2b5a2cb84f448db2020773f1790719":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9e39a4d032864d37866d6f1d0b00179a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_28c05d1fb53b48388dc31ad814cad99c","placeholder":"​","style":"IPY_MODEL_3396fab10708438ead073b497be4f8cc","value":" 440M/440M [00:01&lt;00:00, 245MB/s]"}},"a0fb39408c3c4c22bc017437f96d0e95":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3d37a1518e1744afa151d98ba4edd832","IPY_MODEL_733b149239714b6994bba744598a8f11","IPY_MODEL_9e39a4d032864d37866d6f1d0b00179a"],"layout":"IPY_MODEL_8cbd5f957a72480cbfaf6673dc1aeaef"}},"a4fa70ce328149a7926a2d9e48f9b63f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a56c213ab58943b3b5ea8b38e6181762":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a5c7820c21274dff887d7d9b3e1396e9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"af9a146eaad8459b97ddfa3b3c93f806":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8a1f6b4c04841e4bfd4c3a12fd1f041":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ed50c6e20d6d4cdc832c130c847b4ed7","IPY_MODEL_dbc53083d53f49eca734ac5b29fdd1c8","IPY_MODEL_c125252405a54c0c8e31e6ff9f8ef97f"],"layout":"IPY_MODEL_8f823e1ffb194cc39db5db6fbe0fb607"}},"be391209f44643abab52ced5f7b35c22":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"beef2e942bab404a92bd11a92b9f8500":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c125252405a54c0c8e31e6ff9f8ef97f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f1148fa12cfc4b0abdd293c3a0af87fb","placeholder":"​","style":"IPY_MODEL_1e1c15187a10424e85bdd1d3b1d79fb8","value":" 48.0/48.0 [00:00&lt;00:00, 1.28kB/s]"}},"c499a1f224824bd89ed654ab6d0e2462":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c50c812f8d674fc681816f603f7f19f3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c535c4852bc14902a99fcf34d1b7259e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c6fe571ce2e048bbb127a7c16bddba35":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ccf90499ee4341d1878735ac512765fb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_86bb213084bd40b5926c9bafd4aceae2","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7a358684513b487db5be6c882a08160e","value":570}},"dbc53083d53f49eca734ac5b29fdd1c8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a4fa70ce328149a7926a2d9e48f9b63f","max":48,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c50c812f8d674fc681816f603f7f19f3","value":48}},"e11f977dd30d4f939c316f60d0a4d2e9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_517e12ef1d7c4dae8730ab8241675ec1","placeholder":"​","style":"IPY_MODEL_10f1b660eec74c6984c83f01ec5fae44","value":"vocab.txt: 100%"}},"e2d74b97e6214b648d96889dd51c1fc4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e5b4abfe6592433c9985a15b19f0ef21":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ed27da71341d4374845c64aeed084fee":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ed50c6e20d6d4cdc832c130c847b4ed7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f1087b0da431424c97aa3835e40bc94d","placeholder":"​","style":"IPY_MODEL_9c2b5a2cb84f448db2020773f1790719","value":"tokenizer_config.json: 100%"}},"f1087b0da431424c97aa3835e40bc94d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f1148fa12cfc4b0abdd293c3a0af87fb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f88ba5b8333547ffb7cf6f6ba70e73fd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_53699bdef4e54d7dae26ba0bb1eb93ae","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3739e394957d4bdfbcec9dbea35e6df9","value":466062}},"f966dc370e4746b681d3b44d65eb4279":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe6244f7ffc940ad80fba444df2f05ee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_136faf686c3c4c25a3421aea0b2dad97","IPY_MODEL_ccf90499ee4341d1878735ac512765fb","IPY_MODEL_4c19069e19db40248fc6c64d0461bd49"],"layout":"IPY_MODEL_beef2e942bab404a92bd11a92b9f8500"}}}}},"nbformat":4,"nbformat_minor":0}